{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75135d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os, glob, shutil\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import cv2 as cv, numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbae42c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 DATA_DIR: c:\\Users\\jk316\\practice\\trashnet\\data\\dataset-resized\\dataset-resized\n",
      "하위 폴더 샘플: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
     ]
    }
   ],
   "source": [
    "# 당신의 데이터 최상위 폴더(여기 아래 어딘가에 클래스 폴더 6개가 있음)\n",
    "RAW_ROOT = r\"trashnet/data/dataset-resized\"\n",
    "\n",
    "# 1) 맥 압축 잔여물 제거\n",
    "def clean_mac_artifacts(root: str):\n",
    "    for d in glob.glob(os.path.join(root, \"**\", \"__MACOSX\"), recursive=True):\n",
    "        shutil.rmtree(d, ignore_errors=True)\n",
    "    for p in glob.glob(os.path.join(root, \"**\", \"._*\"), recursive=True):\n",
    "        try: os.remove(p)\n",
    "        except: pass\n",
    "    for p in glob.glob(os.path.join(root, \"**\", \".DS_Store\"), recursive=True):\n",
    "        try: os.remove(p)\n",
    "        except: pass\n",
    "\n",
    "clean_mac_artifacts(RAW_ROOT)\n",
    "\n",
    "# 2) 클래스 폴더 깊이 자동 탐지 (cardboard/glass/metal/paper/plastic/trash 찾기)\n",
    "def find_class_root(root: str):\n",
    "    expected = {\"cardboard\",\"glass\",\"metal\",\"paper\",\"plastic\",\"trash\"}\n",
    "    names = {n for n in os.listdir(root) if os.path.isdir(os.path.join(root,n))}\n",
    "    # 현재 깊이에 클래스 폴더가 보이면 OK\n",
    "    if len(expected & names) >= 4:\n",
    "        return root\n",
    "    # 한 단계 더 들어가서 확인\n",
    "    for n in names:\n",
    "        sub = os.path.join(root, n)\n",
    "        if not os.path.isdir(sub): \n",
    "            continue\n",
    "        sub_names = {m for m in os.listdir(sub) if os.path.isdir(os.path.join(sub,m))}\n",
    "        if len(expected & sub_names) >= 4:\n",
    "            return sub\n",
    "    return root  # 못 찾으면 원래 root 반환(추후 프린트로 확인)\n",
    "\n",
    "DATA_DIR = find_class_root(RAW_ROOT)\n",
    "print(\"사용할 DATA_DIR:\", os.path.abspath(DATA_DIR))\n",
    "print(\"하위 폴더 샘플:\", os.listdir(DATA_DIR)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fad5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash'] 총 이미지: 2528\n"
     ]
    }
   ],
   "source": [
    "valid_ext = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
    "def is_ok(p: str):\n",
    "    name = os.path.basename(p)\n",
    "    ext  = os.path.splitext(name)[1].lower()\n",
    "    return (ext in valid_ext) and (not name.startswith(\"._\")) and (\"__MACOSX\" not in p)\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "full_ds = datasets.ImageFolder(DATA_DIR, transform=tf_train, is_valid_file=is_ok)\n",
    "print(\"클래스:\", full_ds.classes, \"총 이미지:\", len(full_ds))\n",
    "\n",
    "# 무조건 6개 클래스가 떠야 정상!\n",
    "assert set(full_ds.classes) >= {\"cardboard\",\"glass\",\"metal\",\"paper\",\"plastic\",\"trash\"}, \"클래스 폴더 인식 실패\"\n",
    "\n",
    "n = len(full_ds)\n",
    "n_tr = int(0.8*n)\n",
    "train_ds, val_ds = random_split(full_ds, [n_tr, n-n_tr])\n",
    "val_ds.dataset.transform = tf_eval  # 검증은 증강 제거\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01123c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrashClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),  # 128→64\n",
    "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2), # 64→32\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2), # 32→16\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64,128), nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = TrashClassifier(num_classes=len(full_ds.classes)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be6868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] loss=1.7096  val_acc=31.62%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[02] loss=1.5023  val_acc=35.97%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[03] loss=1.4326  val_acc=37.35%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[04] loss=1.3610  val_acc=46.64%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[05] loss=1.3009  val_acc=50.40%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[06] loss=1.2404  val_acc=51.58%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[07] loss=1.1975  val_acc=54.35%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[08] loss=1.1676  val_acc=52.57%\n",
      "[09] loss=1.1140  val_acc=56.72%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[10] loss=1.1055  val_acc=60.08%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[11] loss=1.0747  val_acc=58.70%\n",
      "[12] loss=1.0457  val_acc=59.09%\n",
      "[13] loss=1.0469  val_acc=59.29%\n",
      "[14] loss=1.0358  val_acc=62.25%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[15] loss=0.9819  val_acc=62.45%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[16] loss=0.9994  val_acc=63.44%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[17] loss=0.9646  val_acc=64.43%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[18] loss=0.9601  val_acc=65.22%\n",
      "✔ 저장: model.pth / classes.txt\n",
      "[19] loss=0.9426  val_acc=63.24%\n",
      "[20] loss=0.9484  val_acc=63.04%\n",
      "최고 검증 정확도: 65.22%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "\n",
    "opt  = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "# 과거 잘못된 산출물 제거\n",
    "for f in [\"model.pth\",\"classes.txt\"]:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "\n",
    "best_val = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    run_loss = 0.0\n",
    "    for x,y in train_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = crit(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        run_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(1)\n",
    "            total += y.size(0)\n",
    "            correct += (pred==y).sum().item()\n",
    "    val_acc = correct / max(1,total)\n",
    "    print(f\"[{epoch:02d}] loss={run_loss/len(train_loader):.4f}  val_acc={val_acc*100:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        with open(\"classes.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(full_ds.classes))\n",
    "        print(\"✔ 저장: model.pth / classes.txt\")\n",
    "\n",
    "print(\"최고 검증 정확도:\", f\"{best_val*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbcba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jk316\\AppData\\Local\\Temp\\ipykernel_17204\\3267578312.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infer_model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "with open(\"classes.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    CLASSES = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "# 추론 전용 모델 로드(동일 구조)\n",
    "infer_model = TrashClassifier(num_classes=len(CLASSES)).to(device)\n",
    "infer_model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "infer_model.eval()\n",
    "\n",
    "def preprocess(bgr):\n",
    "    rgb = cv.cvtColor(bgr, cv.COLOR_BGR2RGB)\n",
    "    rgb = cv.resize(rgb, (IMG_SIZE,IMG_SIZE), interpolation=cv.INTER_AREA)\n",
    "    x = rgb.astype(np.float32)/255.0\n",
    "    x = (x-0.5)/0.5\n",
    "    x = np.transpose(x, (2,0,1))\n",
    "    return torch.from_numpy(x).unsqueeze(0).to(device)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "assert cap.isOpened(), \"웹캠을 열 수 없습니다. 인덱스를 1,2 등으로 바꿔보세요.\"\n",
    "\n",
    "smooth = deque(maxlen=5)  # 흔들림 완화\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    with torch.no_grad():\n",
    "        p = torch.softmax(infer_model(preprocess(frame)), dim=1).cpu().numpy()[0]\n",
    "    smooth.append(p)\n",
    "    avg = np.mean(smooth, axis=0)\n",
    "    idx = int(np.argmax(avg))\n",
    "    label, conf = CLASSES[idx], float(avg[idx])\n",
    "    cv.putText(frame, f\"{label} {conf*100:.1f}%\", (10,40),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 3)\n",
    "    cv.imshow(\"Trash Classifier\", frame)\n",
    "    if cv.waitKey(1) == ord('q'): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pracice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
